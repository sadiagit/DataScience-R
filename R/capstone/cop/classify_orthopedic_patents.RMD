---
title: "Classifying patients by analyzing the biomechanical features of orthopedic patients"
author: "Sadia Boksh"
output: pdf_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```

# Introduction

In this project we will use the data set from Kaggle to study the biochemical features of orthopedic patients and classify the patients based on these features. Using this data set, we will train few classification machine learning models to classify patients as belonging to one out of three categories: Normal, Disk Hernia or Spondylolisthesis. We will perform the model fitting on scaled raw data. We will choose the best performing model by analyzing their accuracy.


```{r include=FALSE}
if(!require(tidyverse)) install.packages("tidyverse", repos = "http://cran.us.r-project.org")
if(!require(caret)) install.packages("caret", repos = "http://cran.us.r-project.org")
if(!require(data.table)) install.packages("data.table", repos = "http://cran.us.r-project.org")
if(!require(mlbench)) install.packages("mlbench", repos = "http://cran.us.r-project.org")
if(!require(matrixStats)) install.packages("matrixStats", repos = "http://cran.us.r-project.org")
if(!require(dplyr)) install.packages("dplyr", repos = "http://cran.us.r-project.org")
if(!require(corrplot)) install.packages("corrplot", repos = "http://cran.us.r-project.org")


library(tidyverse)
library(caret)
library(data.table)
library(matrixStats)
library(dplyr)
library(corrplot)

### SET WORKING Directory  - REQUIRED ####
#if in rstudio
setwd(dirname(rstudioapi::getActiveDocumentContext()$path))


# use below if in r for windows
#setwd(getSrcDirectory()[1])

```

# Methods


### Data Exploration

The data set used in this project can be found in https://www.kaggle.com/uciml/biomechanical-features-of-orthopedic-patients. This data set has 310 rows and 7 columns. There are 6 features and 1 response variable. There are no missing values in the data set.

```{r  echo=FALSE, include=FALSE}
df <-  read.csv("ortho_patient.csv")
dim(df)
any(is.na(df))
```

```{r}
head(df)
```

This data set has three categories in response variable. The patients are to be classified into these three categories:

```{r echo=FALSE}
unique(df$class)
```

Below is the table that shows the proportion of patients in each class:

```{r echo=FALSE}

df %>% group_by(class) %>% 
    summarise(n=n()) %>% 
    mutate( prop=n/sum(n))
```
## Plots


Below is the correlation plot: 

```{r echo=FALSE}

#correlation plot
Cor = cor(df[,1:6])

Cor

corrplot(Cor, type="upper", method="ellipse", tl.pos="d")


```

From the plot above we can see pelvic_incidence is highly correlated with sacral_slope.


### Principle Component Analysis

We will apply PCA to explore the variable importance of each feature. Using the summary function we can see the variability explained by each PC:

```{r}

#transform to a matrix
x <- df[, 1:6] %>% as.matrix()

# scale and center the feature matrix
x_centered <- sweep(x, 2, colMeans(x))
scaled_X <- sweep(x_centered, 2, colSds(x), FUN = "/") 


# principal components
pca <- prcomp(scaled_X)
summary(pca)$importance
```

We can plot the first two PCS to see how they explain the variability:

```{r}

data.frame(pca$x[,1:2], class=df$class) %>% 
    ggplot(aes(PC1,PC2, col = class))+
    geom_point() +
    coord_fixed(ratio = 1)+
    stat_ellipse(type="norm", lwd = 1.5)
```


We can see PC1 and PC2 has separated the patients into two categories: Spondylolisthesis and non Spondylolisthesis. Lower PC1 explains Spondylolisthesis and higher PC1 explains either Normal or Hernia.

We can also plot the first 10 PCs:

```{r}
data.frame(pca$x[,1:6], class=df$class) %>% 
    gather(PCs,Value, -class) %>%
    ggplot(aes(PCs,Value, fill = class))+
    geom_boxplot()
```

From the plot above we can see PC1 is not overlapping with other PCs.


## Modeling 

Now we will fit LDA, KNN and Random forest, SVM Linear models to the scaled data set and compare their accuracy. 

First we will split the scaled data set to 80% train set and 20% test set. 80/20 split has been made to be able to train the model with as much data as possible at the same having a decent amount data for testing. 

```{r include=FALSE}
set.seed(1, sample.kind = "Rounding")
test_index <- createDataPartition(df$class, times = 1, p = 0.2, list = FALSE)
test_x <- scaled_X[test_index,]
test_y <- factor(df$class[test_index])
train_x <- scaled_X[-test_index,]
train_y <- factor(df$class[-test_index])
```

### LDA

LDA makes predictions by estimating the probability that a new set of inputs belongs to each class. The class that gets the highest probability is the output class and a prediction is made. LDA model is used in this data set as it can handle continuous independent variable and a categorical dependent variable. 

```{r warning=FALSE, message=FALSE, echo=FALSE}
set.seed(5, sample.kind = "Rounding")
```
```{r warning=FALSE, message=FALSE}
train_lda <- train(train_x, train_y, method = "lda")
pred_lda <-  predict(train_lda,  test_x)
acc_lda <- confusionMatrix(pred_lda,test_y)$overall['Accuracy']
acc_lda
```

### K Nearest Neighbours

KNN algorithm can be used for classification where input consists of the k closest training examples in data set and output is a class membership. An object is classified by the majority vote it gets by its neighbors. The object is assigned to the class most common among its k nearest neighbors.

For KNN, I am using tuning parameter k from 15 to 40 and the default cross validation is performed by taking 25 bootstrap samples comprised of 25% of the observations

```{r warning=FALSE, message=FALSE, echo=FALSE}
set.seed(7, sample.kind = "Rounding")
```

```{r warning=FALSE, message=FALSE}
train_knn <- train(train_x, train_y, method = "knn", 
                    tuneGrid = data.frame(k=c(15:40,2)))
pred_knn <-  predict(train_knn,  test_x)
acc_knn <- confusionMatrix(pred_knn,test_y)$overall['Accuracy']

acc_knn
train_knn$bestTune
ggplot(train_knn, highlight = TRUE)
```

### SVM Linear Model

Support vector machine algorithm creates a line or a hyperplane which separates the data into classes.
For SVM Linear model, I have used tuning parameter C from 1 to 10 and 10 fold cross validation.

```{r warning=FALSE, message=FALSE, echo=FALSE}

set.seed(20, sample.kind = "Rounding")
```
```{r warning=FALSE, message=FALSE}
train_control <- trainControl(method="repeatedcv", number=10, repeats=3)

train_svm <- train(train_x, train_y, method = "svmLinear",
                    tuneGrid = data.frame(C=c(1:10,2)),
                    trControl = train_control)
pred_svm <-  predict(train_svm,  test_x)
acc_svm <- confusionMatrix(pred_svm,test_y)$overall['Accuracy']

acc_svm
train_svm$bestTune

ggplot(train_svm, highlight = TRUE)
```


### Random Forest

Random forest consists of a large number of individual decision trees that operate as an ensemble. Each individual tree in the random forest spits out a class prediction and the class with the most votes becomes our modelâ€™s prediction.
Random forest allows each individual tree to randomly sample from the dataset with replacement, resulting in different trees. This process is known as bagging.

For Random forest, tune grid parameter is mtry (number of variables randomly sampled as candidates at each split) with values from 3 to 13.

```{r warning=FALSE, message=FALSE, echo=FALSE}
set.seed(9, sample.kind = "Rounding")
```
```{r warning=FALSE, message=FALSE}
train_rf <- train(train_x, train_y, method = "rf", 
                  tuneGrid = data.frame(mtry=c(3:13)), importance=TRUE)
pred_rf <-  predict(train_rf,  test_x)
acc_rf <- confusionMatrix(pred_rf,test_y)$overall['Accuracy']
acc_rf
ggplot(train_rf, highlight = TRUE)
```

```{r echo=FALSE}
varImp(train_rf)
```


# Results

Now we can compare the results of different models and their accuracy.

Below is the accuracy table summary:

```{r echo=FALSE, warning=FALSE}
data.frame("Method"= c('LDA','KNN','Random Forest','SVM') ,"Accuracy" =c( acc_lda, acc_knn, acc_rf, acc_svm))
```


# Conclusion

In summary, this analysis shows it is possible to classify the orthopedic patients by analyzing their biochemical features. SVM Linear is the highest performing model with accuracy around 87%. Future work can be done to improve the accuracy above 87%.


