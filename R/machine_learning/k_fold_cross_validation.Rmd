---
title: "Cross Validation (K folds)"
author: "Sadia Boksh"
date: "08/12/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
```
 
# Accuracy using randomly selected columns

Because x and y are completely independent, we should not be able to predict y using x with accuracy greater than 0.5. We can confirm this by running cross-validation using logistic regression to fit the model. Because we have so many predictors, we selected a random sample x_subset when training the model.

```{r}
library(tidyverse)
library(caret)
        
# set.seed(1996) #if you are using R 3.5 or earlier
set.seed(1996, sample.kind="Rounding") #if you are using R 3.6 or later
n <- 1000
p <- 10000
x <- matrix(rnorm(n*p), n, p)
colnames(x) <- paste("x", 1:ncol(x), sep = "_")
y <- rbinom(n, 1, 0.5) %>% factor()

x_subset <- x[ ,sample(p, 100)]

dim(x)
dim(x_subset)
fit <- train(x_subset,y, method = "glm")
fit$results

```

# Accuracy using statistically significant columns
Now, instead of using a random selection of predictors, we are going to search for those that are most predictive of the outcome. We can do this by comparing the values for the  y=1  group to those in the  y=0  group, for each predictor, using a t-test. You can do perform this step like this:

```{r}
#install.packages("BiocManager")
#BiocManager::install("genefilter")
library(genefilter)
tt <- colttests(x, y)
pvals <- tt$p.value
indx <- which(pvals < 0.01)

length(indx)

x_subset_w_sig_col<- x[, indx]
fit_2 <- train(x_subset_w_sig_col, y, method="glm")
fit_2$results
```
# Accuracy using KNN and statistically significant columns
```{r}
fit <- train(x_subset, y, method = "knn", tuneGrid = data.frame(k = seq(101, 301, 25)))
ggplot(fit)
```


we see that despite the fact that x and y are completely independent, we were able to predict y with accuracy higher than 70%. We must be doing something wrong then.We used the entire dataset to select the columns used in the model.

We can check this over training in tissue_gene_expression dataset.

Using k = seq(1,7,2) for tuning parameters. 

```{r}
fit_tissue<- train(tissue_gene_expression$x, tissue_gene_expression$y, method="knn", tuneGrid=data.frame(k = seq(1,7,2)))
fit_tissue$results$k[which.max(fit_tissue$results$Accuracy)]
```

# Bootstrapping

```{r}
library(dslabs)
library(caret)
data(mnist_27)
# set.seed(1995) # if R 3.5 or earlier
set.seed(1995, sample.kind="Rounding") # if R 3.6 or later

indexes <- createResample(mnist_27$train$y, 10)

threes <- map(indexes,function(samples){
  sum(samples == 3)
})
apply(data.frame(unlist(threes)),2,sum)
```

Now we generate a random normal dataset and estimate its 75th quantile statistics using bootstrap method

```{r}

y <- rnorm(100, 0, 1)
qnorm(0.75)
quantile(y, 0.75)

#bootstrapping the dataset 10 time
set.seed(1, sample.kind = "Rounding")
n <- 10000
q_75 <- replicate(n, {
  y <- rnorm(100, 0, 1)
  quantile(y, 0.75)
})

mean(q_75)
sd(q_75)

#bootstrapping the dataset 10000 time
set.seed(1, sample.kind = "Rounding")
y <- rnorm(100, 0, 1)
set.seed(1, sample.kind = "Rounding")
indexes <- createResample(y, 10000)
q <- sapply(indexes, function(samples){
  quantile(y[samples], 0.75)
  
})
mean(q)
sd(q)


```
